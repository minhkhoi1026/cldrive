import json
import os
from tqdm import tqdm
import random
from loguru import logger
import numpy as np
import multiprocessing

from app.runner import KernelRunInstance

'''
input.json already have kernel path + gsize + lsize
=> need to add args parse

need_to_run_grouped_configs[] => run_kernel()
run_kernel() use kernel_path to
    + read kernel_code 
    => use this to read the args too ?? 
    => find relation of exe config and args[] generated by run_mem_analysis.py
'''
KERNEL_DIR = 'kernels' # temporarily parse only code, fixed exe config
KERNEL_CONFIG_PATH = 'default_configs.json'# [......]
ARGS_FOLDER = "backup-mem-analysis/success/" 
BACKUP_DIR = "back-up-cldrive"
SUCCESS_DIR = os.path.join(BACKUP_DIR, "success")
FAIL_DIR = os.path.join(BACKUP_DIR, "fail")
BACKUPED_LIST = set()

TIMEOUT = 60 # 1 minutes
N_RUN = 5

GPU_POOL = [1, 2, 3]
NUM_GPU = len(GPU_POOL)

random.seed(2610)

# logger.remove(0)
rng = np.random.default_rng()

def run_kernel(kernel_configs):
    kernel_path, gsize, lsize, args_sizes = kernel_configs
    #gsizes -> list 
    kernel_id = os.path.splitext(kernel_path)[0]
    
    kernel_code = open(os.path.join(KERNEL_DIR, kernel_path), "r", encoding="utf-8").read()
    
    # for i, gsize in enumerate(gsizes):
    #     # if f"{kernel_id}_{gsize}_{lsize}" in BACKUPED_LIST:
    #     #     continue
    for i, args_size in enumerate(args_sizes): 
        run_instance = KernelRunInstance(kernel_code=kernel_code,
                                            gsize=gsize,
                                            lsize=lsize,
                                            args_values=args_size,
                                            timeout=TIMEOUT)
        result_df, stderr = run_instance.run_n_times(N_RUN)
        if result_df is None:
            with open(os.path.join(FAIL_DIR, f"{kernel_id}_{gsize}_{lsize}.txt"), "w") as f:
                f.write(stderr)
            # if stderr is TIMEOUT, we mark all remaining gsize of this kernel as TIMEOUT
            # if "TIMEOUT" in stderr:
            #     for j in range(i+1, len(gsizes)):
            #         with open(os.path.join(FAIL_DIR, f"{kernel_id}_{gsizes[j]}_{lsize}.txt"), "w") as f:
            #             f.write("TIMEOUT")
            #     break
        else:
            result_df.to_csv(os.path.join(SUCCESS_DIR, f"{kernel_id}_{gsize}_{lsize}_{args_size}.csv"), index=None)

def set_cuda_visible():
    process_number = GPU_POOL[multiprocessing.current_process()._identity[0] - 1]
    os.environ["CUDA_VISIBLE_DEVICES"] = str(process_number)

if __name__ == "__main__":
    # format the input list 
    # if not os.path.exists(CONFIG_PATH):
    #     raise FileNotFoundError(f"Config file not found: {CONFIG_PATH}")

    # # initial list : [(kernel_path, gsize, lsize)]
    # # kernel path = kernel_name.cl 
    # configs = json.load(open(CONFIG_PATH, "r", encoding="utf-8"))
    # args_sizes = json.load(open(ARGS_PATH, "r", encoding="utf-8"))

    # if not os.path.exists(SUCCESS_DIR):
    #     os.makedirs(SUCCESS_DIR, exist_ok=True)
    # if not os.path.exists(FAIL_DIR):
    #     os.makedirs(FAIL_DIR, exist_ok=True)
    # BACKUPED_LIST = set(os.path.splitext(os.path.basename(kernel))[0] for kernel in os.listdir(SUCCESS_DIR))
    # BACKUPED_LIST.update(os.path.splitext(os.path.basename(kernel))[0] for kernel in os.listdir(FAIL_DIR))
    
    # # remove already run configs
    # print(f"Total {len(configs)} kernels in config file")

    # need_to_run_configs = []
    # for kernel_configs in configs:
    #     kernel_path, gsize, lsize = kernel_configs
    #     kernel_id = os.path.splitext(kernel_path)[0]
    #     # if f"{kernel_id}_{gsize}_{lsize}" not in BACKUPED_LIST:
    #     #     need_to_run_configs.append((kernel_path, gsize, lsize))
    #     need_to_run_configs.append((kernel_path, gsize, lsize))
    # print(f"Total {len(need_to_run_configs)} kernels need to run")

    # need_to_run_configs = sorted(need_to_run_configs, key=lambda x: (x[0], x[2], x[1]))
    # # create list which group by (kernel_path, lsize) and increasing gsize
    # # result list [(kernel_path, lsize, [gsize1, gsize2, ...])]
    # need_to_run_grouped_configs = []
    # i = 0
    # while (i < len(need_to_run_configs)):
    #     kernel_path, gsize, lsize = need_to_run_configs[i]
        
    #     group = [gsize]
    #     i += 1
    #     while (i < len(need_to_run_configs) and kernel_path == need_to_run_configs[i][0] and lsize == need_to_run_configs[i][2]):
    #         group.append(need_to_run_configs[i][1])
    #         i += 1
    #     need_to_run_grouped_configs.append((kernel_path, lsize, group))

    # NEW ONE
    kernel_exe_config = json.load(open(KERNEL_CONFIG_PATH, "r", encoding="utf-8"))
    for i, sublist in enumerate(kernel_exe_config[:10]):        
        kernel_name = os.path.splitext(sublist[0])[0]
        global_size = sublist[1]
        local_size = sublist[2]

        filename = f"{kernel_name}_{global_size}_{local_size}.json"

        file_path = os.path.join(ARGS_FOLDER, filename)
        if os.path.isfile(file_path):
            print(f"File found: {file_path}")
            args_size = json.load(open(file_path, "r", encoding="utf-8"))
            kernel_exe_config[i].append(args_size)
            print(kernel_exe_config[i])
        # else:
        #     print(f"File not found: {file_path}")
        # formatted_args_sizes = [', '.join(map(str, sublist)) for sublist in args_sizes]
    
    # need_to_run_grouped_configs[0] += (args_sizes,)
    # print(f"Length to run {len(need_to_run_grouped_configs)}")


    # run in parallel
    with multiprocessing.Pool(
        processes=NUM_GPU, initializer=set_cuda_visible
    ) as pool:
        # Use the pool to map the process_element function to the elements
        # (kernel_path, lsize, [gsize1, gsize2, ...]) -> input of run_kernel()
        list(tqdm(pool.imap(run_kernel, kernel_exe_config[:10]), total=len(kernel_exe_config[:10])))

    
            
